# LLM User Profiler CLI

A Command Line Interface tool that leverages Large Language Models (LLMs) to generate detailed user profiles by analyzing data from your PostgreSQL database and PostHog events.

## üìñ How It Works

The tool operates in a three-phase workflow designed to provide transparency and control over the profiling process:

### 1. Planning Phase (`src/planner.ts`)
The tool starts by understanding your data structure to create a tailored analysis strategy.
-   **Introspection**: It connects to your PostgreSQL database and introspects the public schema to understand available tables and columns.
-   **Context Loading**: Optional markdown context files can be provided to give the LLM domain-specific knowledge.
-   **Plan Generation**: Using the schema and context, the LLM generates an **Analysis Plan** (`analysis_plan.md`). This plan contains:
    -   Analysis goals and specific metrics to extract.
    -   **SQL Queries**: Executable SQL queries targeted at your Postgres database.
    -   **HogQL Queries**: (If configured) Queries for fetching behavioral data from PostHog.
    -   **Profile Schema**: A JSON structure definition for the final user profile.
-   **Review**: You have the opportunity to review and modify the generated plan before execution.

### 2. Execution Phase (`src/executor.ts`)
The tool executes the approved plan to gather raw data.
-   **Query Parsing**: It extracts the `sql` and `hogql` code blocks from the analysis plan.
-   **Execution**:
    -   SQL queries are run against the configured PostgreSQL database.
    -   HogQL queries are sent to the PostHog API.
-   **Data Aggregation**: Results from all queries are aggregated and saved to `interim_results.json`. This serves as the raw data layer for the profiling phase.

### 3. Profiling Phase (`src/profiler.ts`)
The final phase synthesizes the data into human-readable profiles.
-   **Synthesis**: The LLM is fed the `analysis_plan.md` (for context/definitions) and `interim_results.json` (the data).
-   **Generation**: It generates a JSON file (`user_profiles.json`) containing rich user profiles. These profiles combine:
    -   **Hard metrics**: Direct values from the database (e.g., "created 5 projects").
    -   **Inferred Insights**: Qualitative analysis derived from patterns in the data (e.g., "high engagement user", "churn risk").

## üöÄ Quick Start

### Prerequisites
-   Bun runtime
-   Access to an LLM API (via OpenRouter)
-   PostgreSQL connection string
-   (Optional) PostHog API Key & Project ID

### Installation

```bash
# Install dependencies
bun install
```

### Running the Tool

```bash
bun start
```

The CLI acts as an interactive wizard (using **Ink.js**) that guides you through the configuration and the three phases described above.

## ‚öôÔ∏è Configuration

You can configure the tool interactively or by setting environment variables in a `.env` file in your output directory:

-   `OPENROUTER_API_KEY`: Required for LLM access.
-   `DATABASE_URL`: PostgreSQL connection string (e.g., `postgresql://user:pass@localhost:5432/dbname`).
-   `POSTHOG_API_KEY`: (Optional) For PostHog integration.
-   `POSTHOG_PROJECT_ID`: (Optional) PostHog Project ID.
-   `POSTHOG_HOST`: (Optional) Defaults to `https://eu.i.posthog.com` (change to us for üá∫üá∏ü¶Ö).

## üõ†Ô∏è Development

```bash
# Run in development mode
bun dev

# Type check
bun tsc --noEmit
```

## üìÇ Output Files

All artifacts are generated in your specified output directory:

-   `analysis_plan.md`: The strategy and queries generated by the LLM.
-   `interim_results.json`: The raw data fetched from your data sources.
-   `user_profiles.json`: The final, detailed user profiles in JSON format.
